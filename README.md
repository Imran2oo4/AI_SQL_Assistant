# AI-Powered SQL Assistant (AISQL)

Complete Text-to-SQL system with RAG, Groq API, and multi-platform deployment support.

---

## üìã Table of Contents

1. [Overview](#overview)
2. [Features](#features)
3. [Quick Start](#quick-start)
4. [Local Development](#local-development)
5. [Deployment Options](#deployment-options)
6. [Configuration](#configuration)
7. [API Reference](#api-reference)
8. [Troubleshooting](#troubleshooting)

---

## üéØ Overview

AISQL is a production-ready SQL generation system that converts natural language questions into SQL queries using:
- **Groq API** (llama-3.1-70b-versatile) for SQL generation
- **TinyLlama** for local fallback (optional)
- **RAG (Retrieval-Augmented Generation)** for context-aware query generation
- **Auto-correction** for failed queries
- **SQL refinement** and optimization

### Architecture
```
Frontend (Streamlit) ‚Üê ‚Üí Backend (FastAPI) ‚Üê ‚Üí Database (SQLite/MySQL/PostgreSQL)
                              ‚Üì
                         Groq API + RAG
```

---

## ‚ú® Features

### Core Capabilities

| Feature | Description | Status |
|---------|-------------|--------|
| **SQL Generation** | Convert natural language to SQL with schema awareness | ‚úÖ Working |
| **SQL Explanation** | Plain-English explanations of generated queries | ‚úÖ Working |
| **Error Correction** | Automatic retry with corrected SQL on execution failure | ‚úÖ Working |
| **SQL Refinement** | Review and optimize queries for performance | ‚úÖ Working |
| **RAG Integration** | Learn from similar examples in knowledge base | ‚úÖ Working |
| **Multi-Database** | SQLite, MySQL, PostgreSQL support | ‚úÖ Working |
| **Rate Limiting** | Global thread-safe rate limiting (30 RPM) | ‚úÖ Working |
| **Performance Monitoring** | Track API calls, errors, cache hits | ‚úÖ Working |
| **Query Validation** | Syntax checking and security validation | ‚úÖ Working |

### Groq API Features

All features previously available with Gemini API are now implemented with Groq:

#### 1. SQL Generation (`generate_sql_direct`)
- Schema-aware query generation
- RAG example integration
- Exact value matching (uses = not BETWEEN)
- Clean SQL output (no markdown)
- Temperature: 0.1 (deterministic)

#### 2. SQL Explanation (`explain_sql`)
- Non-technical language (2-3 sentences)
- Step-by-step breakdown
- Context-aware with original question
- Temperature: 0.3 (slightly creative)

#### 3. Error Correction (`correct_sql_error`)
- Auto-triggered on execution failure
- Fixes common issues:
  - Column/table name typos
  - Data type mismatches
  - Syntax errors
  - JOIN condition problems
- Returns corrected SQL or None
- Temperature: 0.1 (precise)

#### 4. SQL Refinement (`refine_sql`)
- Correctness validation
- Syntax verification
- Performance optimization
- Schema compliance check
- Temperature: 0.1 (conservative)

### Performance vs Gemini

| Metric | Gemini (Old) | Groq (New) | Improvement |
|--------|--------------|------------|-------------|
| Rate Limit | 15 RPM | 30 RPM | **2x better** |
| Daily Quota | 1,500 | 14,400 | **10x better** |
| Delay Between Calls | 4-5s | 2s | **2x faster** |

---

## üöÄ Quick Start

### Prerequisites
- Python 3.11+
- Docker & Docker Compose (for containerized deployment)
- Groq API key from [console.groq.com](https://console.groq.com)

### 1. Clone Repository
```powershell
git clone <your-repo-url>
cd aisql
```

### 2. Install Dependencies
```powershell
pip install -r requirements.txt
```

### 3. Configure Environment
Create `.env` file in project root:
```env
GROQ_API_KEY=your_groq_api_key_here
GROQ_MODEL=llama-3.1-70b-versatile
AUTO_RETRY_ON_ERROR=true
ENABLE_TINYLLAMA=false
```

### 4. Start Services

#### Option A: Direct Python
```powershell
# Terminal 1 - Backend
uvicorn backend.main:app --host 0.0.0.0 --port 8000

# Terminal 2 - Frontend
streamlit run frontend/app.py
```

#### Option B: Docker Compose (Recommended)
```powershell
docker-compose up -d
```

### 5. Access Application
- **Frontend**: http://localhost:8501
- **Backend API**: http://localhost:8000
- **API Docs**: http://localhost:8000/docs

---

## üê≥ Local Development (Docker)

### Docker Setup

#### File Structure
```
aisql/
‚îú‚îÄ‚îÄ Dockerfile.backend          # Backend container
‚îú‚îÄ‚îÄ Dockerfile.frontend         # Frontend container
‚îú‚îÄ‚îÄ docker-compose.yml          # Orchestration
‚îú‚îÄ‚îÄ .dockerignore              # Exclude unnecessary files
‚îî‚îÄ‚îÄ .env                       # Environment variables
```

### Build and Run

```powershell
# Build images
docker-compose build

# Start all services
docker-compose up -d

# View logs
docker-compose logs -f

# Stop services
docker-compose down

# Rebuild after code changes
docker-compose up -d --build

# Remove all containers and volumes
docker-compose down -v
```

### Individual Service Management

#### Backend Only
```powershell
docker build -f Dockerfile.backend -t aisql-backend .
docker run -p 8000:8000 -e GROQ_API_KEY=your_key aisql-backend
```

#### Frontend Only
```powershell
docker build -f Dockerfile.frontend -t aisql-frontend .
docker run -p 8501:8501 -e BACKEND_URL=http://localhost:8000 aisql-frontend
```

### Volume Persistence

The following directories are mounted as volumes:
- `chromadb_data/` - RAG database storage
- `logs/` - Application logs

Data persists across container restarts.

### Health Check

Backend includes a health check endpoint:
```powershell
curl http://localhost:8000/health
```

---

## ‚òÅÔ∏è Deployment Options

### Option 1: Hugging Face Spaces (Recommended - FREE)

**Why Hugging Face?**
- ‚úÖ **100% FREE** with generous compute
- ‚úÖ **Public URL** automatically generated
- ‚úÖ **No credit card required**
- ‚úÖ **Easy secret management**
- ‚úÖ **Always on** (doesn't sleep)

#### Deploy to Hugging Face (5 minutes)

**Step 1: Create Account**
1. Go to [huggingface.co](https://huggingface.co) and sign up
2. Verify email

**Step 2: Create New Space**
1. Go to [huggingface.co/spaces](https://huggingface.co/spaces)
2. Click **"Create new Space"**
3. Configure:
   - **Name**: `aisql-assistant`
   - **SDK**: Choose **Docker**
   - **Hardware**: **CPU basic** (free)
   - **Visibility**: Public
4. Click **"Create Space"**

**Step 3: Upload Files**

Via Web UI:
1. Click **"Files"** tab ‚Üí **"Add file"** ‚Üí **"Upload files"**
2. Upload these files:
   - `Dockerfile.huggingface` (rename to `Dockerfile`)
   - `start_huggingface.sh`
   - `requirements.txt`
   - `backend/` folder
   - `frontend/` folder
   - `rag/` folder
   - `pipeline/` folder
   - `chromadb_data/` folder

Or via Git:
```powershell
git clone https://huggingface.co/spaces/YOUR_USERNAME/aisql-assistant
cd aisql-assistant

# Copy your project files
cp -r ../aisql/* .

# Rename Dockerfile
mv Dockerfile.huggingface Dockerfile

# Push
git add .
git commit -m "Initial deployment"
git push
```

**Step 4: Add Groq API Key**
1. In Space, click **"Settings"** tab
2. Scroll to **"Repository secrets"**
3. Click **"Add a new secret"**
   - Name: `GROQ_API_KEY`
   - Value: Your Groq API key
4. Click **"Add secret"**

**Step 5: Enable Persistent Storage (Optional)**
1. **Settings** ‚Üí **Storage**
2. Enable **"Persistent storage"**
3. This preserves ChromaDB data across restarts

**Step 6: Wait for Build**
- Hugging Face will automatically build (~5-10 minutes)
- Watch build logs in terminal at bottom

**Step 7: Access Your App! üéâ**
```
https://huggingface.co/spaces/YOUR_USERNAME/aisql-assistant
```

**Share this URL with everyone!**

---

### Option 2: Render (Easy Cloud Deploy)

**Pros**: Free tier, auto-sleep when inactive, simple setup  
**Cons**: Cold starts (30s wake-up time on free tier)

#### Deploy to Render

1. Create account at [render.com](https://render.com)

2. Create `render.yaml`:
```yaml
services:
  - type: web
    name: aisql-backend
    env: docker
    dockerfilePath: ./Dockerfile.backend
    envVars:
      - key: GROQ_API_KEY
        sync: false
    healthCheckPath: /health

  - type: web
    name: aisql-frontend
    env: docker
    dockerfilePath: ./Dockerfile.frontend
    envVars:
      - key: BACKEND_URL
        value: https://aisql-backend.onrender.com
```

3. Connect GitHub repo in Render dashboard
4. Add environment variables in Render UI
5. Deploy automatically on git push

**Access**: `https://aisql-frontend.onrender.com`

---

### Option 3: Azure Container Apps

**Pros**: Enterprise-grade, auto-scaling, managed HTTPS  
**Cons**: Requires Azure account, not free

#### Deploy to Azure

```powershell
# Login
az login

# Create resource group
az group create --name aisql-rg --location eastus

# Create container registry
az acr create --resource-group aisql-rg --name aisqlregistry --sku Basic

# Build and push images
az acr build --registry aisqlregistry --image aisql-backend:latest -f Dockerfile.backend .
az acr build --registry aisqlregistry --image aisql-frontend:latest -f Dockerfile.frontend .

# Create container app environment
az containerapp env create \
  --name aisql-env \
  --resource-group aisql-rg \
  --location eastus

# Deploy backend
az containerapp create \
  --name aisql-backend \
  --resource-group aisql-rg \
  --environment aisql-env \
  --image aisqlregistry.azurecr.io/aisql-backend:latest \
  --target-port 8000 \
  --ingress external \
  --env-vars GROQ_API_KEY=secretref:groq-key \
  --secrets groq-key=your_groq_api_key

# Deploy frontend
az containerapp create \
  --name aisql-frontend \
  --resource-group aisql-rg \
  --environment aisql-env \
  --image aisqlregistry.azurecr.io/aisql-frontend:latest \
  --target-port 8501 \
  --ingress external \
  --env-vars BACKEND_URL=https://aisql-backend.azurecontainerapps.io
```

**Access**: Check output for URLs or run:
```powershell
az containerapp show --name aisql-frontend --resource-group aisql-rg --query properties.configuration.ingress.fqdn
```

---

### Option 4: AWS ECS Fargate

**Pros**: AWS ecosystem, scalable, managed  
**Cons**: Complex setup, not free

#### Deploy to AWS

```powershell
# Install AWS CLI and configure
aws configure

# Create ECR repositories
aws ecr create-repository --repository-name aisql-backend
aws ecr create-repository --repository-name aisql-frontend

# Login to ECR
aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin <account-id>.dkr.ecr.us-east-1.amazonaws.com

# Build and push
docker build -f Dockerfile.backend -t aisql-backend .
docker tag aisql-backend:latest <account-id>.dkr.ecr.us-east-1.amazonaws.com/aisql-backend:latest
docker push <account-id>.dkr.ecr.us-east-1.amazonaws.com/aisql-backend:latest

docker build -f Dockerfile.frontend -t aisql-frontend .
docker tag aisql-frontend:latest <account-id>.dkr.ecr.us-east-1.amazonaws.com/aisql-frontend:latest
docker push <account-id>.dkr.ecr.us-east-1.amazonaws.com/aisql-frontend:latest

# Create ECS cluster
aws ecs create-cluster --cluster-name aisql-cluster

# Create task definitions (see AWS ECS documentation)
# Create services
# Configure Application Load Balancer
```

**Access**: ALB DNS name from AWS console

---

### Option 5: Kubernetes (Enterprise)

**Pros**: Full control, multi-cloud, auto-scaling  
**Cons**: Complex, requires K8s knowledge

#### Kubernetes Manifests

**Backend Deployment** (`k8s/backend-deployment.yaml`)
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: aisql-backend
spec:
  replicas: 2
  selector:
    matchLabels:
      app: aisql-backend
  template:
    metadata:
      labels:
        app: aisql-backend
    spec:
      containers:
      - name: backend
        image: your-registry/aisql-backend:latest
        ports:
        - containerPort: 8000
        env:
        - name: GROQ_API_KEY
          valueFrom:
            secretKeyRef:
              name: aisql-secrets
              key: groq-api-key
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
```

**Frontend Deployment** (`k8s/frontend-deployment.yaml`)
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: aisql-frontend
spec:
  replicas: 2
  selector:
    matchLabels:
      app: aisql-frontend
  template:
    metadata:
      labels:
        app: aisql-frontend
    spec:
      containers:
      - name: frontend
        image: your-registry/aisql-frontend:latest
        ports:
        - containerPort: 8501
        env:
        - name: BACKEND_URL
          value: "http://aisql-backend-service:8000"
```

**Services** (`k8s/services.yaml`)
```yaml
apiVersion: v1
kind: Service
metadata:
  name: aisql-backend-service
spec:
  selector:
    app: aisql-backend
  ports:
  - port: 8000
    targetPort: 8000
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  name: aisql-frontend-service
spec:
  selector:
    app: aisql-frontend
  ports:
  - port: 80
    targetPort: 8501
  type: LoadBalancer
```

**Deploy**:
```powershell
kubectl apply -f k8s/
kubectl get pods
kubectl get services
```

---

## üîß Configuration

### Environment Variables

Create `.env` file in project root:

```env
# Required
GROQ_API_KEY=your_groq_api_key_here

# Optional - Groq Settings
GROQ_MODEL=llama-3.1-70b-versatile    # Default model
AUTO_RETRY_ON_ERROR=true              # Enable auto-correction
RATE_LIMIT_DELAY=2.0                  # Seconds between requests (30 RPM)

# Optional - TinyLlama (Local Fallback)
ENABLE_TINYLLAMA=false                # Disable local model
TINYLLAMA_MODEL_PATH=/path/to/model   # If using TinyLlama

# Optional - Database
DB_TYPE=sqlite                        # sqlite, mysql, postgresql
DB_PATH=./database.db                 # SQLite path
# DB_HOST=localhost                   # For MySQL/PostgreSQL
# DB_PORT=3306                        # Database port
# DB_USER=root                        # Database user
# DB_PASSWORD=password                # Database password
# DB_NAME=mydatabase                  # Database name

# Optional - Backend
BACKEND_HOST=0.0.0.0
BACKEND_PORT=8000
LOG_LEVEL=INFO                        # DEBUG, INFO, WARNING, ERROR

# Optional - Frontend
FRONTEND_PORT=8501
BACKEND_URL=http://localhost:8000     # Backend API URL
```

### Rate Limiting

Groq API has the following limits (free tier):
- **30 requests per minute** (RPM)
- **14,400 requests per day**

The system automatically handles rate limiting with:
- Global shared timestamp across all instances
- Thread-safe locking
- 2-second delay between requests
- Automatic retry on rate limit errors

### Performance Monitoring

Access real-time metrics at:
```
http://localhost:8000/metrics
```

**Metrics tracked**:
- Total queries processed
- Cache hit rate
- Groq API calls and errors
- Average response time
- RAG retrieval success rate

---

## üìñ API Reference

### Backend Endpoints

#### 1. Health Check
```http
GET /health
```

**Response**:
```json
{
  "status": "healthy",
  "timestamp": "2026-01-02T10:30:00Z"
}
```

#### 2. Generate SQL
```http
POST /generate
```

**Request**:
```json
{
  "question": "Show all students with age greater than 20",
  "use_groq": true,
  "groq_api_key": "your_key",
  "use_rag": true,
  "top_k": 3
}
```

**Response**:
```json
{
  "sql": "SELECT * FROM students WHERE age > 20",
  "explanation": "This query retrieves all records from the students table where the age column is greater than 20.",
  "model": "groq",
  "execution_time": 1.23,
  "rag_examples_used": 2
}
```

#### 3. Execute Query
```http
POST /execute
```

**Request**:
```json
{
  "sql": "SELECT * FROM students WHERE age > 20",
  "question": "Show all students with age greater than 20"
}
```

**Response**:
```json
{
  "results": [
    {"id": 1, "name": "Alice", "age": 22},
    {"id": 2, "name": "Bob", "age": 21}
  ],
  "columns": ["id", "name", "age"],
  "row_count": 2,
  "execution_time": 0.05
}
```

#### 4. Get Schema
```http
GET /schema
```

**Response**:
```json
{
  "tables": [
    {
      "name": "students",
      "columns": [
        {"name": "id", "type": "INTEGER", "nullable": false},
        {"name": "name", "type": "TEXT", "nullable": false},
        {"name": "age", "type": "INTEGER", "nullable": true}
      ],
      "primary_key": ["id"],
      "foreign_keys": []
    }
  ]
}
```

#### 5. Performance Metrics
```http
GET /metrics
```

**Response**:
```json
{
  "total_queries": 150,
  "cache_hit_rate": 0.42,
  "avg_response_time": 1.5,
  "groq_calls": 87,
  "groq_errors": 2,
  "groq_error_rate": 0.023,
  "rag_retrievals": 130,
  "rag_success_rate": 0.95
}
```

---

## üõ†Ô∏è Troubleshooting

### Common Issues

#### 1. "Groq API key is invalid"
**Problem**: API key not accepted  
**Solution**:
- Verify key at [console.groq.com](https://console.groq.com)
- Check `.env` file has correct key
- Restart backend after updating `.env`

#### 2. "Rate limit exceeded"
**Problem**: Too many requests to Groq API  
**Solution**:
- System auto-retries after delay
- Wait 60 seconds for rate limit reset
- Check `RATE_LIMIT_DELAY` in `.env` (should be 2.0)

#### 3. Docker build fails
**Problem**: Build errors during docker-compose  
**Solution**:
```powershell
# Clear Docker cache
docker system prune -a

# Rebuild
docker-compose build --no-cache
docker-compose up -d
```

#### 4. Frontend can't connect to backend
**Problem**: "Connection refused" or timeout  
**Solution**:
- Check backend is running: `curl http://localhost:8000/health`
- Verify `BACKEND_URL` in frontend environment
- For Docker: Use service names (`http://backend:8000`)
- For local: Use `http://localhost:8000`

#### 5. RAG examples not found
**Problem**: No similar examples retrieved  
**Solution**:
- Populate RAG database:
  ```powershell
  python scripts/populate_rag_examples.py
  ```
- Check `chromadb_data/` folder exists
- Enable persistent storage in deployment

#### 6. SQL execution fails repeatedly
**Problem**: Even with auto-correction  
**Solution**:
- Check database schema matches queries
- Verify column names are case-sensitive
- Review error logs: `logs/errors.jsonl`
- Check `AUTO_RETRY_ON_ERROR=true` in `.env`

#### 7. Hugging Face Space won't start
**Problem**: Build fails or container crashes  
**Solution**:
- Check build logs at bottom of Space page
- Verify `Dockerfile` (not `Dockerfile.huggingface`)
- Ensure `start_huggingface.sh` is executable
- Check secret `GROQ_API_KEY` is set
- Enable persistent storage for ChromaDB

#### 8. Out of memory in deployment
**Problem**: Container crashes due to RAM  
**Solution**:
- Reduce `top_k` RAG examples (edit `backend/main.py`)
- Disable TinyLlama: `ENABLE_TINYLLAMA=false`
- Upgrade hardware (Hugging Face: Settings ‚Üí Hardware)

---

## üìä Platform Comparison

| Feature | Hugging Face | Render | Azure | AWS | Kubernetes |
|---------|--------------|--------|-------|-----|------------|
| **Free Tier** | ‚úÖ Yes | ‚úÖ Yes (sleeps) | ‚ùå No | ‚ùå No | Depends on cluster |
| **Always On (Free)** | ‚úÖ Yes | ‚ùå No | ‚ùå No | ‚ùå No | - |
| **Public URL** | ‚úÖ .hf.space | ‚úÖ .onrender.com | ‚úÖ .azurecontainerapps.io | ‚úÖ ELB DNS | ‚úÖ Ingress |
| **Setup Time** | 5 min | 5 min | 20 min | 30 min | 60 min |
| **Persistent Storage** | ‚úÖ Free | ‚úÖ $1/GB | ‚úÖ Included | ‚úÖ EBS | ‚úÖ PVC |
| **Auto-scaling** | ‚úÖ Yes | ‚úÖ Yes | ‚úÖ Yes | ‚úÖ Yes | ‚úÖ Yes |
| **GPU Support** | ‚úÖ Yes | ‚ùå No | ‚úÖ Yes | ‚úÖ Yes | ‚úÖ Yes |
| **Custom Domain** | ‚úÖ Pro ($9/mo) | ‚úÖ Free | ‚úÖ Free | ‚úÖ Free | ‚úÖ Ingress |
| **Best For** | **AI/ML demos** | Web apps | Enterprise | AWS ecosystem | Multi-cloud |

**Recommendation**: Start with **Hugging Face Spaces** (free, easiest, always-on), then migrate to Azure/AWS for production enterprise needs.

---

## üîê Security Best Practices

1. **API Keys**:
   - Never commit `.env` files to git
   - Use secrets management in production (K8s secrets, Azure Key Vault, AWS Secrets Manager)
   - Rotate keys regularly

2. **SQL Injection Protection**:
   - Backend validates all queries before execution
   - Parameterized queries used for user inputs
   - SQL validation layer checks for dangerous keywords

3. **Rate Limiting**:
   - Global rate limiting prevents abuse
   - Per-user limits can be added at API gateway level

4. **HTTPS**:
   - Always use HTTPS in production
   - Hugging Face, Render, Azure, AWS provide auto-HTTPS

5. **Database Access**:
   - Use read-only database users when possible
   - Restrict network access to database
   - Enable audit logging

---

## üìà Performance Optimization

### Backend
- **Query Caching**: Repeated queries served from cache (LRU with 100 entry limit)
- **Connection Pooling**: Database connections reused (pool size: 5-20)
- **Async Operations**: Non-blocking I/O for API calls
- **RAG Optimization**: Semantic search with ChromaDB for fast retrieval

### Frontend
- **Session State**: User context preserved across interactions
- **Lazy Loading**: Components loaded on demand
- **Error Boundaries**: Graceful error handling prevents crashes

### Database
- **Indexes**: Add indexes on frequently queried columns
- **Query Optimization**: Groq refinement suggests better queries
- **Schema Design**: Normalize for read-heavy workloads

---

## üìù Logging

### Log Files

```
logs/
‚îú‚îÄ‚îÄ errors.jsonl          # Error events
‚îú‚îÄ‚îÄ feedback.jsonl        # User feedback
‚îî‚îÄ‚îÄ interactions.jsonl    # Query logs
```

### Log Format

```json
{
  "timestamp": "2026-01-02T10:30:00Z",
  "level": "INFO",
  "message": "SQL query generated successfully",
  "data": {
    "question": "Show all students",
    "model": "groq",
    "execution_time": 1.23,
    "cache_hit": false
  }
}
```

### View Logs

```powershell
# Docker
docker-compose logs -f backend

# Local
tail -f logs/errors.jsonl
```

---

## üß™ Testing

### Manual Testing

1. **SQL Generation**:
   - Test: "Show all students"
   - Verify: Valid SELECT query returned

2. **Error Correction**:
   - Test: Generate query with typo in table name
   - Verify: Auto-correction fixes and retries

3. **RAG Integration**:
   - Test: Ask similar question to existing example
   - Verify: RAG examples used (check logs)

4. **Performance**:
   - Test: Repeated identical queries
   - Verify: Cache hit rate increases

### Automated Testing

```powershell
# Run tests (if test suite exists)
pytest tests/

# Load testing
# Use tools like Apache Bench or Locust
```

---

## üìö Additional Resources

- [Groq API Documentation](https://console.groq.com/docs)
- [Hugging Face Spaces Docs](https://huggingface.co/docs/hub/spaces)
- [Docker Documentation](https://docs.docker.com)
- [FastAPI Documentation](https://fastapi.tiangolo.com)
- [Streamlit Documentation](https://docs.streamlit.io)

---

## üìÑ License

Apache 2.0 (or your chosen license)

---

## ü§ù Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open Pull Request

---

## üí¨ Support

- **Issues**: Open GitHub issues for bugs
- **Questions**: Use GitHub Discussions
- **Email**: your-email@example.com

---

## ‚úÖ Quick Checklist

### Before Local Development
- [ ] Python 3.11+ installed
- [ ] Docker installed (if using Docker)
- [ ] Groq API key obtained
- [ ] `.env` file created
- [ ] Dependencies installed (`pip install -r requirements.txt`)

### Before Deployment
- [ ] Code tested locally
- [ ] Environment variables configured
- [ ] Secrets set up in platform
- [ ] Database populated (if using pre-seeded data)
- [ ] RAG examples ingested
- [ ] Health checks passing

### After Deployment
- [ ] Public URL accessible
- [ ] Backend health check works
- [ ] Frontend loads correctly
- [ ] Can connect to database
- [ ] SQL generation working
- [ ] Auto-correction tested
- [ ] Performance metrics tracking

---

## üéâ Success!

Your AISQL system is now ready to convert natural language to SQL queries!

**Next Steps**:
1. **Try it**: Ask a question and generate SQL
2. **Monitor**: Check `/metrics` for performance data
3. **Share**: Send your URL to users
4. **Optimize**: Review logs and improve based on usage patterns

**Enjoy your AI-powered SQL assistant! üöÄ**
